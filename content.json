{"meta":{"title":"Dang's blog","subtitle":"Where randomness is the king","description":null,"author":"Dang Ha The Hien","url":"https://nikasa1889.github.io"},"pages":[{"title":"CV - updated February 2017","date":"2017-03-19T23:15:00.000Z","updated":"2017-03-20T00:10:35.446Z","comments":true,"path":"CV/CV.html","permalink":"https://nikasa1889.github.io/CV/CV.html","excerpt":"","text":"Download: https://nikasa1889.github.io/content/CV_Feb2017.pdf"},{"title":"Categories","date":"2016-11-05T16:09:41.622Z","updated":"2016-11-05T16:09:41.622Z","comments":true,"path":"categories/index.html","permalink":"https://nikasa1889.github.io/categories/index.html","excerpt":"","text":""},{"title":"Tags","date":"2016-11-05T16:09:41.622Z","updated":"2016-11-05T16:09:41.622Z","comments":true,"path":"tags/index.html","permalink":"https://nikasa1889.github.io/tags/index.html","excerpt":"","text":""},{"title":"About","date":"2017-02-27T16:10:47.000Z","updated":"2017-04-06T23:01:28.512Z","comments":true,"path":"about/index.html","permalink":"https://nikasa1889.github.io/about/index.html","excerpt":"","text":"To be short, I’m a child who always wants to improve his model about the world. To be more specific, I consider myself to be a bit of every thing: a statistician, a data engineer, a machine learning practitioner, an AI researcher. I probably can come up with more. I learn and do whatever it needs to broaden my view and knowledge about general intelligence. I’m a Ph.D. student at the University of Oslo and working for a company in Norway called eSmart Systems at the same time. My job is to design a big data analytics platform for IoT applications (e.g., Smart Grid), the products that my company is selling. I do multivariate time-series analysis and modeling, including forecasting and clustering. Recently, I get involved a lot in an exciting AI project called the “Drone project”, where we develop automatic line inspection solution for Utility companies using drones. It requires applying Deep Learning and AI technologies in many parts, which make me super delighted. This blog is an attempt to publish my thinking about statistics, machine learning, and artificial intelligence in general. Many posts will be just a set of organized random thoughts, while some others will be about how I have solved some technical issues when getting my job done. My research interest is a mix of many things, including : Environmental forecasting with large-scale sensor networks: Large-scale multivariate time-series models: Recurrent and Convolutional Neural Networks: Automatic Programming, Reinforcement Learning: General AI, Knowledge Representation, Learning Theories, Computational Models"},{"title":"Record Handwriting","date":"2016-07-13T18:46:25.000Z","updated":"2016-11-06T15:59:18.835Z","comments":true,"path":"record-handwriting/index.html","permalink":"https://nikasa1889.github.io/record-handwriting/index.html","excerpt":"","text":"playbackInterruptCommand = \"\"; $(document).bind(\"pageinit\", function() { $(\"#pauseBtn\").hide(); $(\"#playBtn\").hide(); drawing = new RecordableDrawing(\"canvas1\"); $(\"#recordBtn\").click(function(){ var btnTxt = $(\"#recordBtn .ui-btn-text\").text(); if (btnTxt == 'Stop') stopRecording(); else startRecording(); }); $(\"#playBtn\").click(function(){ var btnTxt = $(\"#playBtn .ui-btn-text\").text(); if (btnTxt == 'Stop') stopPlayback(); else startPlayback(); }); $(\"#pauseBtn\").click(function(){ var btnTxt = $(\"#pauseBtn .ui-btn-text\").text(); if (btnTxt == 'Pause') { pausePlayback(); } else if (btnTxt == 'Resume') { resumePlayback(); } }); $(\"#clearBtn\").click(function(){ drawing.clearCanvas(); }); }); function stopRecording() { $(\"#recordBtn .ui-btn-text\").text(\"Record\"); $(\"#playBtn\").show(); $(\"#clearBtn\").show(); $(\"#pauseBtn\").hide(); drawing.stopRecording(); } function startRecording() { $(\"#recordBtn .ui-btn-text\").text(\"Stop\"); $(\"#playBtn\").hide(); $(\"#pauseBtn\").hide(); $(\"#clearBtn\").hide(); drawing.startRecording(); } function stopPlayback() { playbackInterruptCommand = \"stop\"; } function startPlayback() { drawing.playRecording(function() { //on playback start $(\"#playBtn .ui-btn-text\").text(\"Stop\"); $(\"#recordBtn\").hide(); $(\"#pauseBtn\").show(); $(\"#clearBtn\").hide(); playbackInterruptCommand = \"\"; }, function(){ //on playback end $(\"#playBtn .ui-btn-text\").text(\"Play\"); $(\"#playBtn\").show(); $(\"#recordBtn\").show(); $(\"#clearBtn\").show(); $(\"#pauseBtn\").hide(); }, function() { //on pause $(\"#pauseBtn .ui-btn-text\").text(\"Resume\"); $(\"#recordBtn\").hide(); $(\"#playBtn\").hide(); $(\"#clearBtn\").hide(); }, function() { //status callback return playbackInterruptCommand; }); } function pausePlayback() { playbackInterruptCommand = \"pause\"; } function resumePlayback() { playbackInterruptCommand = \"\"; drawing.resumePlayback(function(){ $(\"#pauseBtn .ui-btn-text\").text(\"Pause\"); $(\"#pauseBtn\").show(); $(\"#recordBtn\").hide(); $(\"#clearBtn\").hide(); $(\"#playBtn\").show(); }); } Record Play Pause Clear"}],"posts":[{"title":"A guide to receptive field arithmetic for Convolutional Neural Networks","slug":"A-guide-to-receptive-field-arithmetic-for-Convolutional-Neural-Networks","date":"2017-04-06T23:12:28.000Z","updated":"2017-04-06T23:58:27.947Z","comments":true,"path":"2017/04/07/A-guide-to-receptive-field-arithmetic-for-Convolutional-Neural-Networks/","link":"","permalink":"https://nikasa1889.github.io/2017/04/07/A-guide-to-receptive-field-arithmetic-for-Convolutional-Neural-Networks/","excerpt":"","text":"The receptive field is perhaps one of the most important concepts in Convolutional Neural Networks (CNNs) that deserves more attention from the literature. All of the state-of-the-art object recognition methods design their model architectures around this idea. However, to my best knowledge, currently there is no complete guide on how to calculate and visualize the receptive field information of a CNN. This post fills in the gap by introducing a new way to visualize feature maps in a CNN that exposes the receptive field information, accompanied by a complete receptive field calculation that can be used for any CNN architecture. I’ve also implemented a simple program to demonstrate the calculation so that anyone can start computing the receptive field and gain better knowledge about the CNN architecture that they are working with. To follow this post, I assume that you are familiar with the CNN concept, especially the convolutional and pooling operations. You can refresh your CNN knowledge by going through the paper “A guide to convolution arithmetic for deep learning [1]”. It will not take you more than half an hour if you have some prior knowledge about CNNs. This post is in fact inspired by that paper and uses similar notations. The fixed-sized CNN feature map visualizationThe receptive field is defined as the region in the input space that a particular CNN’s feature is looking at (i.e. be affected by). A receptive field of a feature can be fully described by its center location and its size. Figure 1 shows some receptive field examples. By applying a convolution C with kernel size k = 3x3, padding size p = 1x1, stride s = 2x2 on an input map 5x5, we will get an output feature map 3x3 (green map). Applying the same convolution on top of the 3x3 feature map, we will get a 2x2 feature map (orange map). The number of output features in each dimension can be calculated using the following formula, which is explained in detail in [1]. Figure 1: Two ways to visualize CNN feature maps. In all cases, we uses the convolution C with kernel size k = 3x3, padding size p = 1x1, stride s = 2x2. (Top row) Applying the convolution on a 5x5 input map to produce the 3x3 green feature map. (Bottom row) Applying the same convolution on top of the green feature map to produce the 2x2 orange feature map. (Left column) The common way to visualize a CNN feature map. Only looking at the feature map, we do not know where a feature is looking at (the center location of its receptive field) and how big is that region (its receptive field size). It will be impossible to keep track of the receptive field information in a deep CNN. (Right column) The fixed-sized CNN feature map visualization, where the size of each feature map is fixed, and the feature is located at the center of its receptive field. The left column of Figure 1 shows a common way to visualize a CNN feature map. In that visualization, although by looking at a feature map, we know how many features it contains. It is impossible to know where each feature is looking at (the center location of its receptive field) and how big is that region (its receptive field size). The right column of Figure 1 shows the fixed-sized CNN visualization, which solves the problem by keeping the size of all feature maps constant and equal to the input map. Each feature is then marked at the center of its receptive field location. Because all features in a feature map have the same receptive field size, we can simply draw a bounding box around one feature to represent its receptive field size. We don’t have to map this bounding box all the way down to the input layer since the feature map is already represented in the same size of the input layer. Figure 2 shows another example using the same convolution but applied on a bigger input map — 7x7. We can either plot the fixed-sized CNN feature maps in 3D (Left) or in 2D (Right). Notice that the size of the receptive field in Figure 2 escalates very quickly to the point that the receptive field of the center feature of the second feature layer covers almost the whole input map. This is an important insight which was used to improve the design of a deep CNN. Figure 2: Another fixed-sized CNN feature map representation. The same convolution C is applied on a bigger input map with i = 7x7. I drew the receptive field bounding box around the center feature and removed the padding grid for a clearer view. The fixed-sized CNN feature map can be presented in 3D (Left) or 2D (Right). Receptive Field ArithmeticTo calculate the receptive field in each layer, besides the number of features n in each dimension, we need to keep track of some extra information for each layer. These include the current receptive field size r, the distance between two adjacent features (or jump) j, and the center coordinate of the first feature (start). When applying a convolution with the kernel size k, the padding size p, and the stride size s, the attributes of the output layer can be calculated by the following equations: The first equation calculates the number of output futures based on the number of input features and the convolution properties. This is the same equation presented in [1]. The second equation calculates the jump in the output feature map, which is equal to the jump in the input map times the number of input features that you jump over when applying the convolution (the stride size). The third equation calculates the receptive field size of the output feature map, which is equal to the area that covered by k input features (k-1)*j_in plus the extra area that covered by the receptive field of the input feature that on the border. The fourth equation calculates the center position of the receptive field of the first output feature, which is equal to the center position of the first input feature plus the distance from the location of the first input feature to the center of the first convolution (k-1)/2*j_in minus the padding space p*j_in. Note that we need to multiply with the jump of the input feature map in both cases to get the actual distance/space. The first layer is the input layer, which always has n = image size, r = 1, j = 1, and start = 0.5. Note that in Figure 3, I used the coordinate system in which the center of the first feature of the input layer is at 0.5. By applying the four above equations recursively, we can calculate the receptive field information for all feature maps in a CNN. Figure 3 shows an example of how these equations work. Figure 3: Applying the receptive field calculation on the example given in Figure 1. The first row shows the notations and general equations, while the second and the last row shows the process of applying it to calculate the receptive field of the output layer given the input layer information. I’ve also created a small python program that calculates the receptive field information for all layers in a given CNN architecture. It also allows you to input the name of any feature map and the index of a feature in that map, and returns the size and location of the corresponding receptive field. The following figure shows an output example when we use the AlexNet. The code is provided at the end of this post.","categories":[],"tags":[],"keywords":[]},{"title":"Wake-On-Lan through the internet","slug":"Wake-On-Lan-through-the-internet","date":"2017-03-09T16:14:00.000Z","updated":"2017-04-06T22:47:18.271Z","comments":true,"path":"2017/03/09/Wake-On-Lan-through-the-internet/","link":"","permalink":"https://nikasa1889.github.io/2017/03/09/Wake-On-Lan-through-the-internet/","excerpt":"My daily work usually starts by opening an SSH connection to a server, running a docker image (with RStudio Server or Jupyter on it), and analyzing data or programming directly on the browser. It was always convenient like that until I got sudden disconnection last month. Suddenly anything stops working,","text":"My daily work usually starts by opening an SSH connection to a server, running a docker image (with RStudio Server or Jupyter on it), and analyzing data or programming directly on the browser. It was always convenient like that until I got sudden disconnection last month. Suddenly anything stops working, and I wasted several hours hopelessly trying to fix it. When I went home, I figured out that the electricity in my apartment was very unstable due to a small construction upstairs. Of course, a simple solution is getting a UPS (Uninterruptible Power Supply), but I was fascinated by the idea that maybe I can turn on my server over the internet. That is like having the server’s power switch with me all the time. It would be so cool, especially when I’m away for an extended period and don’t want to waste money on the energy bills. This story is about how I’ve done it. You can have a look at my final network setup first. My Network with the Wifi Repeater to provide wired connection to the server, and an insider to help me wake the server through the internet Step 1: Satisfy hardware requirements In most motherboards, there is a function called “Wake-on-Lan” (WOL). WoL works by sending a packet of data called a Magic Packet™ to a target machine. When the packet is received, the target machine’s network interface wakes-up the rest of the computer. However, I recognized that I cannot wake-up my server through its wireless interface (I’m using a USB wireless adapter). It turned out that the Magic Packet must be sent to the motherboard’s built-in Ethernet port since it’s the only thing awake when the whole machine off. I fixed the situation by using a Wifi Repeater, and connect it to the server through an Ethernet cable. You can skip this step if your machine is using a wired connection. Step 2: Make Wake-On-Lan work on Lan. As the name suggested, WOL is designed to wake-up a machine through a local network. So you have to be in the same network with your target device to make it work. In this step, we will try to do just that.First, you have to turn on the WOL feature on your motherboard. Enter the BIOS setup and look for “ Wake up on PCI event” or “ Wake up on LAN” and enable it. Second, on Ubuntu, you have to know your default interface, check if it supports WOL, and turn on the feature. The whole process can be done as following: 1$ docker exec -it $DockerID /bin/bash To make the setting sustains after rebooting, you need to add the last command above to the interface’s configuration in etc/network/interfaces. You can read more in here.Now, let’s test it. You can use a mobile app called “Wake-on-Lan” in Android (there are similar apps for iOS, but I haven’t tested it). It can automatically scan your local network and list all of the connected devices. You just search for your machine, add it, and then you can send the magic packet to it whenever you want. Try to turn off your target machine and wake it up by your phone.You can add the device manually if you know its mac address and broadcast address. They are 9E:65:F9:0E:29:FB and 192.168.0.255 in my case. You can use the ifconfig command to find out that information. Note that you will need your mac address to wake up your machine through the internet. Step 3: Make Wake-On-Lan work through the internet. Note that your router must have a static IP (e.g., 82.164.3.27) to complete this step. There are many solutions to send the magic packet through the internet. I’ve listed them below from the easiest to the hardest (sometimes the only) solution: First solution: If your router supports forwarding the magic packet (Port 7 or 9 UDP), you are lucky. You can just forward any packet from port 7 or 9 UDP to your target device. Some routers even allow forwarding broadcast packet. You can use this website to wake up your server. However, as far as I know, most of the popular commercial routers do not support this (my case). Remember to make a DHCP reservation for your server, so that its IP will not change after reconnecting. Second solution: You can check if you can install a better firmware for your router. For marketing purpose, many router producers hide functionalities on their products. You can install a third-party firmware to unlock all of these. I highly recommend the OpenWrt. Check if your router is supported by OpenWrt here. Third solution: If your router is not that good, you will need an insider. It’s a device that is always on and connects to your local network. Then you can SSH to your insider over the internet and let it send the magic package for you. In my case, I use a cheap Raspberry Pi 3 (which I already use for controlling other things). I’m using OpenWrt on it, and run the etherwake command as following: 1$ etherwake 9E:65:F9:0E:29:FB eth0 The first argument is the mac address of the target machine, while the second argument is the network interface of the insider that will send the package. It should be its default interface. You can check this link for more detail. Note that your insider can be any device, running any OS. As long as you can SSH to it through the internet, it should work. Remember to configure port forwarding for the insider’s SSH port, so that you can SSH to it from anywhere. So, that’s it. I hope you enjoy the story. Leave a comment if you have any trouble following it.","categories":[],"tags":[{"name":"Hobby","slug":"Hobby","permalink":"https://nikasa1889.github.io/tags/Hobby/"},{"name":"System Configuration","slug":"System-Configuration","permalink":"https://nikasa1889.github.io/tags/System-Configuration/"}],"keywords":[]},{"title":"Automate opening bash shell on a running docker","slug":"Automate-opening-bash-shell-on-a-running-docker-1","date":"2017-03-06T15:57:00.000Z","updated":"2017-04-06T22:40:32.632Z","comments":true,"path":"2017/03/06/Automate-opening-bash-shell-on-a-running-docker-1/","link":"","permalink":"https://nikasa1889.github.io/2017/03/06/Automate-opening-bash-shell-on-a-running-docker-1/","excerpt":"","text":"Setting up a development environment that is deployable has always been a complicated task for data scientists. In my case, I have a bunch of environments, each designed for different purposes. For example, I use R for time-series forecasting and descriptive statistics, while using Python (with Scikit-Learn, Tensorflow, and sometimes Caffe) for deep learning and reinforcement learning. It is almost impossible for me to have one environment for every purpose. Docker has saved my life. It’s an elegant solution for every trouble you’ve ever got with environment settings. If you have not read about it, you should do it now. To make my life easier, I’ve created several bash scripts to automate some docker tasks that I usually do. You can check the list here. My favorite script is to open a bash shell on a running docker. To execute the bash sell command on a particular docker, you need to know its ID, like this: 1234$ route #Get name of the default interface, for example: eth0$ sudo ethtool eth0 #Look for \"Supports Wake-on: g\" line, which means WOL supported$ sudo ethtool -s eth0 wol g #Enable WOL Since the DockerID will change every time you run a new image, you need to list all of the running dockers and pick the one that you want to access to. This is not a big deal, until you have to do it hundreds times. The following script will list and let you pick your target docker. A simple solution for a small daily issue.","categories":[],"tags":[{"name":"Data Engineer","slug":"Data-Engineer","permalink":"https://nikasa1889.github.io/tags/Data-Engineer/"}],"keywords":[]},{"title":"Hello, World!","slug":"hello-world","date":"2017-02-26T23:44:00.000Z","updated":"2017-04-06T23:03:18.891Z","comments":true,"path":"2017/02/27/hello-world/","link":"","permalink":"https://nikasa1889.github.io/2017/02/27/hello-world/","excerpt":"","text":"It has been very long time ago since I decided that I need to have a personal blog. But my procrastination power was so high that I could not manage to do so earlier. And now, since my Ph.D. is moving slowly to its end, the need to have an updated detail CV in the form of a blog has finally created enough kick-ass force. I’m a child who always wants to improve his model about the world. To be more specific, I consider myself to be a bit of every thing: a statistician, a data engineer, a machine learning practitioner, an AI researcher. I probably can come up with more. I learn and do whatever it needs to broaden my view and knowledge about general intelligence. I’m a Ph.D. student at the University of Oslo and working for a company in Norway called eSmart Systems at the same time. My job is to design a big data analytics platform for IoT applications (e.g., Smart Grid), the products that my company is selling. I do multivariate time-series analysis and modeling, including forecasting and clustering. Recently, I get involved a lot in an exciting AI project called the “Drone project”, where we develop automatic line inspection solution for Utility companies using drones. It requires applying Deep Learning and AI technologies in many parts, which make me super delighted. This blog is an attempt to publish my thinking about statistics, machine learning, and artificial intelligence in general. Many posts will be just a set of organized random thoughts, while some others will be about how I have solved some technical issues when getting my job done. I will try to have correct references for any idea that I would ever come up with. But sometimes, some ideas emerge naturally after I have consumed enough information from many sources. At that point, searching back for all of the sources would be impossible for me. It would not be hard for you to find some ideas in this blog that use weird vocabulary. The ideas might have been studied extensively for many years without my notice. Please tell me when that happens, I would be very appreciated.","categories":[],"tags":[{"name":"Hobby","slug":"Hobby","permalink":"https://nikasa1889.github.io/tags/Hobby/"}],"keywords":[]}]}